{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DWCDataIngest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfOgKwzUxu6d"
      },
      "outputs": [],
      "source": [
        "!pip install boto3\n",
        "!pip install hana_ml\n",
        "!pip install replace"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For DWC\n",
        "import boto3\n",
        "import replace\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "import hana_ml.dataframe as dataframe\n",
        "#Establish DWC Space Open SQL Connection\n",
        "conn = dataframe.ConnectionContext(address = '', #Provide your OpenSQL Host here\n",
        "                                   port = 443, \n",
        "                                   user = '', #Provide your OpenSQL container Username here\n",
        "                                   password = '', #Provide your OpenSQL contianer password here\n",
        "                                   encrypt = 'true'\n",
        "                                  )\n",
        "\n",
        "#Get the Access Keys and Secret Keys for AWS S3 Buckets\n",
        "session = boto3.Session( \n",
        "         aws_access_key_id='', #Provide your AWS Access key here\n",
        "         aws_secret_access_key='')#Provide your AWS Secret  key here\n",
        "\n",
        "#Then use the session to get the resource\n",
        "s3 = session.resource('s3')\n",
        "#provide the S3 bucketname\n",
        "my_bucket = s3.Bucket('dwcdmp') #Provide your AWS S3 Bucketname here\n",
        "#loop around all files in the bucket and insert it into DWC Space Open SQL container\n",
        "#Make sure you just have csv files in the bucket mentioned at line 24\n",
        "for objects in my_bucket.objects.all():\n",
        "    key = objects.key\n",
        "#replace .csv from the file name while ingesting the csvs as tables in DWC \n",
        "    keystr = key.replace(\".csv\",\"\")\n",
        "    print(keystr)\n",
        "    csvfile = pd.read_csv(objects.get()['Body'])\n",
        "    print (csvfile)\n",
        "    df_remote = dataframe.create_dataframe_from_pandas(connection_context = conn, \n",
        "                                                   pandas_df = csvfile, \n",
        "                                                   table_name = keystr,\n",
        "                                                   force = True,\n",
        "                                                   replace = True)"
      ],
      "metadata": {
        "id": "KZYnYxtExxz0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}